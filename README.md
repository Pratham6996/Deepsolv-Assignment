Update #1 Created the database model <br /> 
  Created model.py consisting of 4 classes with reference to the db tables 


Update #2 Created the Company Scraper  <br /> 
  Company scraper that scrapes data like name, url, description, website, industry, followers, headcount, specialties, profile_picture



Update #3 Created Post Scraper




Update #4 Created Comments Scraper



Final Update <br /> 

During the development process, I initially explored public APIs for web scraping and selected the ProxyCurl API. Based on this API, I designed and implemented a database schema. However, after completing the initial setup, I discovered that ProxyCurl is a paid service, which required me to restart the project from scratch.

To proceed, I developed custom web scrapers instead. After rebuilding the database, I completed the model.py file, defining four table classes for data storage. Subsequently, I implemented scrapers for company information, posts, and comments. However, while working on the post and comments scraper, I encountered irregularities that required optimization. Due to time constraints, I was unable to finalize this optimization and had to submit the project in an incomplete state.
